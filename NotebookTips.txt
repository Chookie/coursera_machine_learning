* Autocomplete
Tab = autocomplete key
Shift-Tab = tooltip help

* Import the graphlab library 
* graphlab is commercial and part of Dato
import graphlab

* Load data 
* SFrame is a graphlab data structure that allows loading of large datasets and can use disk if not enough memory
* Seems to be written by Dato but is open source, not sure of license.
data = graphlab.SFrame('file.data')

* View Data
data

* View tail and head
data.tail()
data.head()

* View column
sf['age']

* View graph lab canvas (seperate browser window)
sf.show()

* Render graphs in-place in the notebook rather then separate browser window
graphlab.canvas.set_target('ipynb')

* View category view from canvas (now in place after above command)
sf['age'].show(view='Categorical')

sf['age'].mean()
sf['age'].max()

* Create new column
sf['Full Name'] = sf['First Name'] + ' ' + sf['Last Name']

* Do calculation on column
sf['age'] + 2

* To actually save use 
sf['age'] = sf['age'] + 2

* Create functions
def transform_country(country):
    if country == 'USA':
        return 'United States'
    else:
        return country

* Apply function
sf['Country'].apply(transform_country)

* Save result of function
sf['Country'] = sf['Country'].apply(transform_country)

* Show chart
sales.show(view='Scatter Plot', x='sqft_living', y='price')

* Split data into training and test data 
*  .8 = 80% split seed = random split is psuedo random number gemerator so to ensure you always have same results. 
*  Set to any number you want. Just setting to 0 for here.
*  So each time we run this notebook the split will be done in the same way.
train_data,test_data = sales.random_split(.8,0)


* Create model using prebuilt graphlab algorithm
sqft_model= graphlab.linear_regression.create(train_data, target='price', features=['sqft_living'])



